{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Linkedin Job Postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train a model to predict the salary for a job posting, the minimum amount of data needed was a training set of job postings (containing a job location, description etc.) labelled with salary estimates. This data was obtained by scraping data science job postings from Linkedin. Job postings were scraped from Linkedin specifically because there were 2-3x more postings with salary estimates on Linkedin than on Glassdoor. \n",
    "\n",
    "The Linkedin job posting scraper was written using Selenium. The script searched for data science jobs worldwide, from any posting date. Linkedin returns 40 pages worth of job postings and the scraper selected each of these postings (25 per page, 1000 in total) and scraped the company name, job title, location, href, salary and description. The scraped information was stored in a dataframe. This dataframe was filtered so as to only keep rows (job postings) for which a salary estimate was given.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the linkedin job posting scraper module. \n",
    "\n",
    "import scraping_linkedin_job_postings as scraper\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If too many jobs are scraped consecutively, Linkedin detects the scraping and the job postings no longer scrape properly. Therefore, 3 pages of job search results will be scraped at a time. Every 3 pages worth of job postings will be stored in a df and the dfs will be concatenated together. ### Scraping Job Postings into DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Job Postings into DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameter values for the scraper. \n",
    "## Scraping only 3 pages at a time. \n",
    "\n",
    "chromedriver_path = '/Users/isabellanguyen/predicting ds job salaries/chromedriver'\n",
    "username = 'nymdayo@gmail.com'\n",
    "password = 'happy23!'\n",
    "search_url = 'https://www.linkedin.com/jobs/search/?f_SB2=21&geoId=101174742&keywords=data%20scientist&location=Canada'\n",
    "num_of_pages = 3\n",
    "PROXYVAR = \"200.0.40.134:8080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling the scraper on a set of 3 pages of job postings. \n",
    "\n",
    "canada_linkedin_jobs_pages_1_to_3 = scraper.scraper(chromedriver_path, PROXYVAR, username, password, search_url, num_of_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing each df of 3 pages worth of job postings as a pickle object. \n",
    "\n",
    "pickle.dump(canada_linkedin_jobs_pages_1_to_3, open(\"canada_linkedin_jobs_pages_1_to_3.pkl\", \"wb\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DFs Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading all the pickled dfs and concatenating them together. \n",
    "\n",
    "## Initializing empty list to which each df corresponding to 3 pages worth of job postings will be appended. \n",
    "\n",
    "list_of_dfs = []\n",
    "\n",
    "## Loading in and adding df of first 8 pages of job postings to the list. \n",
    "\n",
    "linkedin_jobs_pages_1_to_8 = pickle.load(open(\"worldwide_linkedin_jobs_pages_1_to_8.pkl\", \"rb\"))\n",
    "list_of_dfs.append(linkedin_jobs_pages_1_to_8)\n",
    "\n",
    "## Loading in and adding dfs corresponding to each set of 3 pages of job postings from pages 9 to 40 to the list. \n",
    "\n",
    "x = 9\n",
    "while x < 39:\n",
    "    df = pickle.load(open(\"worldwide_linkedin_jobs_pages_\" + str(x) + \"_to_\" + str(x+2) + \".pkl\", \"rb\"))\n",
    "    list_of_dfs.append(df)\n",
    "    x += 3\n",
    "linkedin_jobs_pages_39_to_40 = pickle.load(open(\"worldwide_linkedin_jobs_pages_39_to_40.pkl\", \"rb\"))\n",
    "list_of_dfs.append(linkedin_jobs_pages_39_to_40)\n",
    "\n",
    "## Concatenating all the dfs together into one larger df. \n",
    "\n",
    "df = pd.concat(list_of_dfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing any job postings that don't have a salary estimate. \n",
    "\n",
    "df = df[df['salary'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>href</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>Data Scientist - TikTok Ads</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/2148228403/...</td>\n",
       "      <td>$144,000/yr</td>\n",
       "      <td>TikTok is the leading destination for short-fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Fremont, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/2147874276/...</td>\n",
       "      <td>$107,000/yr</td>\n",
       "      <td>THE ROLE\\n\\nTesla's mission is to accelerate t...</td>\n",
       "      <td>[ Contribute on all the stages of Data Science...</td>\n",
       "      <td>Seniority Level\\nEntry level\\nIndustry\\nAutomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Data Scientist, Finance</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/2016420647/...</td>\n",
       "      <td>$150,000/yr</td>\n",
       "      <td>Facebook's mission is to give people the power...</td>\n",
       "      <td>[Apply your expertise in quantitative analysis...</td>\n",
       "      <td>Industry\\nInternet\\nEmployment Type\\nFull-time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/1988976314/...</td>\n",
       "      <td>$130,000/yr</td>\n",
       "      <td>Job Description\\n\\nThe New York Times is commi...</td>\n",
       "      <td>[ Reframe newsroom and business objectives as ...</td>\n",
       "      <td>Seniority Level\\nMid-Senior level\\nIndustry\\nO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cerebri AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/1984995996/...</td>\n",
       "      <td>CA$88,300/yr</td>\n",
       "      <td>About Cerebri AI Cerebri AI CVX platform uses ...</td>\n",
       "      <td>[Experience working with and creating data arc...</td>\n",
       "      <td>Seniority Level\\nEntry level\\nIndustry\\nInform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Data Scientist - Strategic Data Solutions</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/1991635599/...</td>\n",
       "      <td>$115,000/yr</td>\n",
       "      <td>Summary\\n\\nImagine what you could do here. At ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Industry\\nConsumer Electronics\\nEmployment Typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/2023622992/...</td>\n",
       "      <td>$155,000/yr</td>\n",
       "      <td>Facebook's mission is to give people the power...</td>\n",
       "      <td>[Build pragmatic, scalable, and statistically ...</td>\n",
       "      <td>Industry\\nInternet\\nEmployment Type\\nFull-time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/1991684708/...</td>\n",
       "      <td>$134,000/yr</td>\n",
       "      <td>Description\\n\\nExcited by using massive amount...</td>\n",
       "      <td>[ Understand the customer’s business need and ...</td>\n",
       "      <td>Industry\\nComputer Software Information Techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>PlayStation</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/2149521530/...</td>\n",
       "      <td>$139,000/yr</td>\n",
       "      <td>PlayStation isn’t just the Best Place to Play ...</td>\n",
       "      <td>[Building models to predict customer behaviors...</td>\n",
       "      <td>Seniority Level\\nInternship\\nIndustry\\nCompute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Lockheed Martin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Shelton, CT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/2014612647/...</td>\n",
       "      <td>$112,000/yr</td>\n",
       "      <td>Description:Performs exploratory research and ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Seniority Level\\nEntry level\\nIndustry\\nConstr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       company                                      title  \\\n",
       "0                       TikTok                Data Scientist - TikTok Ads   \n",
       "1                        Tesla                             Data Scientist   \n",
       "2                     Facebook                    Data Scientist, Finance   \n",
       "3           The New York Times                             Data Scientist   \n",
       "4                   Cerebri AI                             Data Scientist   \n",
       "..                         ...                                        ...   \n",
       "254                      Apple  Data Scientist - Strategic Data Solutions   \n",
       "255                   Facebook                    Research Data Scientist   \n",
       "256  Amazon Web Services (AWS)                             Data Scientist   \n",
       "257                PlayStation                      Data Scientist Intern   \n",
       "258            Lockheed Martin                             Data Scientist   \n",
       "\n",
       "              location                                               href  \\\n",
       "0    Mountain View, CA  https://www.linkedin.com/jobs/view/2148228403/...   \n",
       "1          Fremont, CA  https://www.linkedin.com/jobs/view/2147874276/...   \n",
       "2       Menlo Park, CA  https://www.linkedin.com/jobs/view/2016420647/...   \n",
       "3         New York, NY  https://www.linkedin.com/jobs/view/1988976314/...   \n",
       "4          Toronto, ON  https://www.linkedin.com/jobs/view/1984995996/...   \n",
       "..                 ...                                                ...   \n",
       "254         Austin, TX  https://www.linkedin.com/jobs/view/1991635599/...   \n",
       "255       Bellevue, WA  https://www.linkedin.com/jobs/view/2023622992/...   \n",
       "256    Jersey City, NJ  https://www.linkedin.com/jobs/view/1991684708/...   \n",
       "257      San Mateo, CA  https://www.linkedin.com/jobs/view/2149521530/...   \n",
       "258        Shelton, CT  https://www.linkedin.com/jobs/view/2014612647/...   \n",
       "\n",
       "           salary                                        description  \\\n",
       "0     $144,000/yr  TikTok is the leading destination for short-fo...   \n",
       "1     $107,000/yr  THE ROLE\\n\\nTesla's mission is to accelerate t...   \n",
       "2     $150,000/yr  Facebook's mission is to give people the power...   \n",
       "3     $130,000/yr  Job Description\\n\\nThe New York Times is commi...   \n",
       "4    CA$88,300/yr  About Cerebri AI Cerebri AI CVX platform uses ...   \n",
       "..            ...                                                ...   \n",
       "254   $115,000/yr  Summary\\n\\nImagine what you could do here. At ...   \n",
       "255   $155,000/yr  Facebook's mission is to give people the power...   \n",
       "256   $134,000/yr  Description\\n\\nExcited by using massive amount...   \n",
       "257   $139,000/yr  PlayStation isn’t just the Best Place to Play ...   \n",
       "258   $112,000/yr  Description:Performs exploratory research and ...   \n",
       "\n",
       "                                                skills  \\\n",
       "0                                                   []   \n",
       "1    [ Contribute on all the stages of Data Science...   \n",
       "2    [Apply your expertise in quantitative analysis...   \n",
       "3    [ Reframe newsroom and business objectives as ...   \n",
       "4    [Experience working with and creating data arc...   \n",
       "..                                                 ...   \n",
       "254                                                 []   \n",
       "255  [Build pragmatic, scalable, and statistically ...   \n",
       "256  [ Understand the customer’s business need and ...   \n",
       "257  [Building models to predict customer behaviors...   \n",
       "258                                                 []   \n",
       "\n",
       "                                               details  \n",
       "0                                                       \n",
       "1    Seniority Level\\nEntry level\\nIndustry\\nAutomo...  \n",
       "2    Industry\\nInternet\\nEmployment Type\\nFull-time...  \n",
       "3    Seniority Level\\nMid-Senior level\\nIndustry\\nO...  \n",
       "4    Seniority Level\\nEntry level\\nIndustry\\nInform...  \n",
       "..                                                 ...  \n",
       "254  Industry\\nConsumer Electronics\\nEmployment Typ...  \n",
       "255  Industry\\nInternet\\nEmployment Type\\nFull-time...  \n",
       "256  Industry\\nComputer Software Information Techno...  \n",
       "257  Seniority Level\\nInternship\\nIndustry\\nCompute...  \n",
       "258  Seniority Level\\nEntry level\\nIndustry\\nConstr...  \n",
       "\n",
       "[259 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The final, concatenated df. \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Final Job Postings DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickling the final df. \n",
    "\n",
    "pickle.dump(df, open(\"all_worldwide_datascience_jobs_linkedin.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Glassdoor Company Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enrich the training set with additional features that may be able to predict job salary, company information corresponding to the hiring companies found in the scraped job postings was scraped from Glassdoor.  \n",
    "\n",
    "The Glassdoor scraper, which was also written using selenium, did a company search for each company and scraped the company size, company type (public, private, etc.), company industry, company revenue, company rating, recommend to a friend rating, ceo approval rating and interview difficulty rating. The scraped information was stored in a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the glassdoor scraper module. \n",
    "\n",
    "import glassdoor_company_info_scraper as gd_scraper\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If too many companies are scraped consecutively, Glassdoor detects the scraping and the company info no longer scrapes properly. Therefore, only a subset of the companies will be scraped at a time. The company info corresponding to each subset of companies will be stored in a df and the dfs will be concatenated together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Glassdoor Company Infos into DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading in the full list of company names to be scraped.\n",
    "\n",
    "company_names = pickle.load(open(\"company_names.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing a subset of the company names to be scraped. \n",
    "\n",
    "company_names_256_to_258 = company_names[256:259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished scraping company # 1\n",
      "finished scraping company # 2\n",
      "finished scraping company # 3\n"
     ]
    }
   ],
   "source": [
    "## Calling the scraper on the subset of company names. \n",
    "\n",
    "df = gd_scraper.scrape_glassdoor_company_info(company_names_256_to_258)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickling the df containing the company info for the subset of company names. \n",
    "\n",
    "pickle.dump(df, open(\"gd_scraped_companies_256_to_258.pkl\", \"wb\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DFs Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Listing the names of the pickled dfs for each subset of companies that were scraped at a time. \n",
    "\n",
    "gd_pkl_files = [\"gd_scraped_companies_0_to_44.pkl\", \"gd_scraped_companies_101_to_140.pkl\", \"gd_scraped_companies_141_to_200.pkl\", \n",
    "\"gd_scraped_companies_201_to_217.pkl\", \"gd_scraped_companies_218_to_222.pkl\", \"gd_scraped_companies_223_to_226.pkl\",\n",
    "\"gd_scraped_companies_227_to_230.pkl\", \"gd_scraped_companies_231_to_235.pkl\", \"gd_scraped_companies_236_to_240.pkl\",\n",
    "\"gd_scraped_companies_241_to_245.pkl\", \"gd_scraped_companies_246_to_250.pkl\", \"gd_scraped_companies_251_to_255.pkl\",\n",
    "\"gd_scraped_companies_256_to_258.pkl\", \"gd_scraped_companies_45_to_71.pkl\", \"gd_scraped_companies_72_to_100.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function which loads in each pickled df, appends it to a list of dfs and then concatenates all the dfs together. \n",
    "\n",
    "def concat_dfs(file_list):\n",
    "    list_of_dfs = []\n",
    "    for pkl in file_list:\n",
    "        df = pickle.load(open(pkl, \"rb\"))\n",
    "        list_of_dfs.append(df)\n",
    "    df = pd.concat(list_of_dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_dfs(gd_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>industry</th>\n",
       "      <th>revenue</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "      <th>ceo_approval</th>\n",
       "      <th>interview_difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Palo Alto, CA (US)</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>Company - Public (TSLA)</td>\n",
       "      <td>Transportation Equipment Manufacturing</td>\n",
       "      <td>$2 to $5 billion (CAD) per year</td>\n",
       "      <td>3.5</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Park, CA (US)</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>Company - Public (FB)</td>\n",
       "      <td>Internet</td>\n",
       "      <td>$5 to $10 billion (CAD) per year</td>\n",
       "      <td>4.4</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>Company - Public (NYT)</td>\n",
       "      <td>News Outlets</td>\n",
       "      <td>$1 to $2 billion (CAD) per year</td>\n",
       "      <td>3.8</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Cerebri AI</td>\n",
       "      <td>Austin, TX (US)</td>\n",
       "      <td>1 to 50 employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>3.9</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Limetree</td>\n",
       "      <td>Sarasota, FL (US)</td>\n",
       "      <td>1 to 50 employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Hotel &amp; Resorts</td>\n",
       "      <td>Less than $1 million (CAD) per year</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Teck Resources Limited</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>5001 to 10000 employees</td>\n",
       "      <td>Company - Public (TCK)</td>\n",
       "      <td>Mining</td>\n",
       "      <td>$10+ billion (CAD) per year</td>\n",
       "      <td>3.9</td>\n",
       "      <td>73</td>\n",
       "      <td>95</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>Company - Public (ACN)</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>$10+ billion (CAD) per year</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Figma</td>\n",
       "      <td>San Francisco, CA (US)</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>$10 to $25 million (CAD) per year</td>\n",
       "      <td>4.7</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Figma</td>\n",
       "      <td>San Francisco, CA (US)</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>$10 to $25 million (CAD) per year</td>\n",
       "      <td>4.7</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company            headquarters             company_size  \\\n",
       "0                   TikTok                      -1                       -1   \n",
       "1                    Tesla      Palo Alto, CA (US)         10000+ employees   \n",
       "2                 Facebook     Menlo Park, CA (US)         10000+ employees   \n",
       "3       The New York Times       New York, NY (US)   1001 to 5000 employees   \n",
       "4               Cerebri AI         Austin, TX (US)        1 to 50 employees   \n",
       "..                     ...                     ...                      ...   \n",
       "22                Limetree       Sarasota, FL (US)        1 to 50 employees   \n",
       "23  Teck Resources Limited           Vancouver, BC  5001 to 10000 employees   \n",
       "24               Accenture             Toronto, ON         10000+ employees   \n",
       "25                   Figma  San Francisco, CA (US)      51 to 200 employees   \n",
       "26                   Figma  San Francisco, CA (US)      51 to 200 employees   \n",
       "\n",
       "               company_type                                 industry  \\\n",
       "0                        -1                                       -1   \n",
       "1   Company - Public (TSLA)   Transportation Equipment Manufacturing   \n",
       "2     Company - Public (FB)                                 Internet   \n",
       "3    Company - Public (NYT)                             News Outlets   \n",
       "4         Company - Private  Enterprise Software & Network Solutions   \n",
       "..                      ...                                      ...   \n",
       "22        Company - Private                          Hotel & Resorts   \n",
       "23   Company - Public (TCK)                                   Mining   \n",
       "24   Company - Public (ACN)                               Consulting   \n",
       "25        Company - Private             Computer Hardware & Software   \n",
       "26        Company - Private             Computer Hardware & Software   \n",
       "\n",
       "                                revenue company_rating recommend_to_a_friend  \\\n",
       "0                                    -1             -1                    -1   \n",
       "1       $2 to $5 billion (CAD) per year            3.5                    59   \n",
       "2      $5 to $10 billion (CAD) per year            4.4                    90   \n",
       "3       $1 to $2 billion (CAD) per year            3.8                    80   \n",
       "4              Unknown / Non-Applicable            3.9                    75   \n",
       "..                                  ...            ...                   ...   \n",
       "22  Less than $1 million (CAD) per year            3.0                    -1   \n",
       "23          $10+ billion (CAD) per year            3.9                    73   \n",
       "24          $10+ billion (CAD) per year            4.0                    79   \n",
       "25    $10 to $25 million (CAD) per year            4.7                    94   \n",
       "26    $10 to $25 million (CAD) per year            4.7                    94   \n",
       "\n",
       "   ceo_approval interview_difficulty  \n",
       "0            -1                  2.7  \n",
       "1            75                  2.9  \n",
       "2            94                  3.1  \n",
       "3            95                  2.9  \n",
       "4            80                  2.4  \n",
       "..          ...                  ...  \n",
       "22           -1                   -1  \n",
       "23           95                  2.8  \n",
       "24           87                  2.8  \n",
       "25           90                  3.1  \n",
       "26           90                  3.1  \n",
       "\n",
       "[249 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The final, concatenated df.\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Final Company Infos DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickling the full company infos df. \n",
    "\n",
    "pickle.dump(df, open(\"all_gd_company_infos.pkl\", \"wb\")) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
